\documentclass[12pt]{report}

% Packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{color}
\usepackage{longtable}
\usepackage{hyperref}
\definecolor{lightgray}{rgb}{0.95,0.95,0.95}
\lstnewenvironment{code}{\lstset{language=R, backgroundcolor=\color{lightgray},keywordstyle=\color{blue}, linewidth = \linewidth, xleftmargin= 1cm,xrightmargin= 1cm,breaklines= true,basicstyle=\scriptsize, frame=single,numbers=left, tabsize=12, literate=
  {á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1
  {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
  {à}{{\`a}}1 {è}{{\`e}}1 {ì}{{\`i}}1 {ò}{{\`o}}1 {ù}{{\`u}}1
  {À}{{\`A}}1 {È}{{\'E}}1 {Ì}{{\`I}}1 {Ò}{{\`O}}1 {Ù}{{\`U}}1
  {ä}{{\"a}}1 {ë}{{\"e}}1 {ï}{{\"i}}1 {ö}{{\"o}}1 {ü}{{\"u}}1
  {Ä}{{\"A}}1 {Ë}{{\"E}}1 {Ï}{{\"I}}1 {Ö}{{\"O}}1 {Ü}{{\"U}}1
  {â}{{\^a}}1 {ê}{{\^e}}1 {î}{{\^i}}1 {ô}{{\^o}}1 {û}{{\^u}}1
  {Â}{{\^A}}1 {Ê}{{\^E}}1 {Î}{{\^I}}1 {Ô}{{\^O}}1 {Û}{{\^U}}1
  {œ}{{\oe}}1 {Œ}{{\OE}}1 {æ}{{\ae}}1 {Æ}{{\AE}}1 {ß}{{\ss}}1
  {ű}{{\H{u}}}1 {Ű}{{\H{U}}}1 {ő}{{\H{o}}}1 {Ő}{{\H{O}}}1
  {ç}{{\c c}}1 {Ç}{{\c C}}1 {ø}{{\o}}1 {å}{{\r a}}1 {Å}{{\r A}}1
  {€}{{\EUR}}1 {£}{{\pounds}}1}}{}





\usepackage{setspace}
\usepackage{lipsum}  % To generate dummy text for testing (remove in final version)
\usepackage{fontenc}  % For proper font encoding
\usepackage{times}    % Use Times New Roman font
\usepackage{geometry} % Adjust margins
\usepackage{pdfpages}
\usepackage[backend=biber,style=apa,sorting=nyt]{biblatex}
\usepackage{csquotes}  % Pour la gestion correcte des citations
\usepackage{hyperref}

\addbibresource{Impact of the prediction markets.bib}

% Page size and margins
\geometry{a4paper, left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% Eviter les alinéas
\setlength{\parindent}{0pt}  % Désactive l'indentation de tous les paragraphes

% Line spacing
\renewcommand{\baselinestretch}{1.5}  % 1.5 line spacing

% Numérotation des sections sans chapitre
\setcounter{secnumdepth}{3} % Permet la numérotation jusqu'au sous-sous-section
\setcounter{tocdepth}{3}    % Inclure jusqu'à quel niveau dans la table des matières
\renewcommand{\thesection}{\arabic{section}} % Sections numérotées comme 1, 2, 3...
\renewcommand{\thesubsection}{\arabic{section}.\arabic{subsection}} % Sous-sections 1.1, 1.2...

% En-têtes et pieds de page
\pagestyle{fancy}
\fancyhf{}
\fancyhead[R]{\thepage.} % Numéro de page en haut à droite
\renewcommand{\headrulewidth}{0pt} % Pas de ligne sous l'en-tête



\begin{document}


% Include the title page PDF
\includepdf[pages={1}]{Analyzing.pdf}


\chapter*{Abstract}

This thesis investigates the relationship between prediction market signals and stock returns through a comparative modeling framework. By contrasting global (XGBoost) and local (ARIMA/ARIMAX) forecasting approaches, we examine whether prediction markets generate informational value for financial forecasting and under what conditions this value is most pronounced. Using data from Kalshi prediction markets and a diverse set of U.S. equities and ETFs, we implement a rigorous walk-forward validation strategy to evaluate model performance. Our analysis reveals significant differences in how prediction market signals influence various financial instruments, with important implications for both individual stocks and diversified portfolios. The findings have practical implications for data-driven investment firms, suggesting that prediction market signals can enhance forecasting precision when properly integrated into asset-specific models. The study contributes to the financial forecasting literature by demonstrating how alternative data sources can be systematically integrated into time series models while highlighting the importance of model granularity in capturing relationships between prediction market signals and asset returns.



\chapter*{Acknowledgments}

I express my sincere gratitude to Delphia for the trust they have placed in me throughout this project. Their support has been invaluable and I am especially grateful for the data they provided which formed the backbone of my research.\\

I would also like to extend my heartfelt thanks to Professor Vande Kerckhove for his guidance, feedback and constant encouragement. His expertise has been instrumental in shaping this research and helping me navigate the complexities of this topic.\\

Finally, I would like to acknowledge all those who have contributed to this project, either directly or indirectly. Your support, insight and encouragement have been greatly appreciated. I am grateful to each one of you.



\tableofcontents

\newpage \section{Introduction}

In a rapidly evolving financial landscape, the role of information in shaping market behavior has become increasingly significant. One of the most intriguing and complex challenges is understanding the relationship between prediction markets and their influence on stock returns movements. This thesis addresses the problem of quantifying how predictive signals derived from prediction markets impact stock returns.

\subsection{The current world of prediction markets and stock returns}

In today's financial world, markets are flooded with a wide range of information that can impact investor behavior (\cite{li_effect_2014}). Prediction markets, also known as event futures or information markets, aggregate individual opinions and probabilities about future events, offering valuable signals about the direction of various economic, political or social factors (\cite{waitz_corporate_2013}; \cite{wolfers_prediction_2004}). These markets provide a unique opportunity for investors to gauge future expectations and anticipate market movements.

\subsection{Research question}

This thesis focuses on the research question: \textit{How do prediction markets signals affect stock returns?} To answer this, we explore the potential mechanisms through which these signals influence investor behavior and, by extension, the market valuation of assets. By investigating prediction markets signals, this research aims to build a comprehensive model for stock returns prediction that accounts for the full spectrum of information available to investors.\\

To address this question, we adopt a comparative modeling strategy. Specifically, we assess the relevance and performance of a global modeling approach — a single regression model applied across all stocks, incorporating both returns and exogenous variables common to all assets — versus a stock-specific model, where a distinct model is trained for each individual stock. This methodology enables to determine whether a shared structure, enriched by exogenous information from prediction markets, can generalize across different stocks, or whether asset-specific nuances require tailored models.


\newpage
\subsection{Managerial relevance}

This research holds substantial managerial relevance for Delphia, a Canadian fintech specializing in data-driven investment strategies. The implications are outlined below : \\

\textbf{1. Enhanced data-driven investment strategies:}  
By analyzing how predictive signals from prediction markets influence stock returns, Delphia can refine its investment models. Integrating these signals into algorithms could enhance decision-making processes and potentially improve portfolio performance (\cite{waitz_corporate_2013}; \cite{berg2003results}).\\

\textbf{2. Improved forecasting accuracy:}  
Prediction markets aggregate public sentiment and probabilities about future events, offering valuable insights to anticipate market trends. By combining these signals with Delphia's existing data models, the accuracy of stock price predictions could be significantly improved, leading to more informed investment decisions and better risk management (\cite{tetlock2007giving}).\\

\textbf{3. Detection of market inefficiencies and early trends:}  
This research can aid Delphia in identifying market inefficiencies and emerging trends by leveraging prediction market data. This proactive approach could allow the company to capitalize on shifts in market dynamics before competitors.\\

\textbf{4. Risk management optimization:}  
Incorporating prediction market signals would bolster Delphia's ability to detect potential risks during periods of volatility or uncertainty. This enhanced risk management capability could help protect the company's portfolios from significant losses and reduce exposure to high-risk investments.\\

\textbf{5. Innovation in investment products:}  
The findings could inspire the development of new financial products that utilize prediction market signals. For instance, funds tailored to exploit trends from these markets could offer clients innovative, high-return investment options.\\

\textbf{6. Competitive advantage through strategic information use:}  
Expanding Delphia's data integration to include prediction markets could provide a distinct competitive edge. By harnessing diverse information sources, the company can position itself as a leader in identifying and acting on emerging trends, attracting clients and increasing its market presence.\\

Overall, this research aligns closely with Delphia's mission of leveraging data to inform investment decisions. The insights gained can optimize strategies, improve predictive accuracy and strengthen the company's position in the fintech sector.


\subsection{Thesis structure}

This thesis is structured into eight chapters, each contributing to the overarching objective of assessing the impact of prediction market signals on stock returns through a comparative modeling framework. Chapter 2 provides a comprehensive literature review, covering prediction markets, stock price behavior, and the theoretical foundations such as the Efficient Market Hypothesis and behavioral finance. Chapter 3 introduces the methodological framework, detailing the comparative use of global models (via XGBoost) and local models (via ARIMA/ARIMAX), and formulates the research hypotheses. Chapter 4 describes the data sources, preprocessing procedures, and the integration of prediction market signals with financial return data. Chapter 5 presents the implementation of the forecasting models, including technical specifications, walk-forward validation, and model calibration. Chapter 6 analyzes the empirical results, comparing model performance and testing the hypotheses statistically using metrics like RMSE and the Diebold-Mariano test. Chapter 7 discusses key findings, methodological lessons, and limitations, while reflecting on the broader implications for financial forecasting. Finally, Chapter 8 concludes the research by summarizing the main insights, outlining contributions to both research and practice, and suggesting avenues for future investigation.
\\


\newpage
\section{Literature review}
This section examines previous theories and research on the valuation of information and its influence on financial markets. It reviews key studies, theoretical frameworks and findings relevant to understanding the connection between prediction markets and stock market responses.



\subsection{Prediction markets}

Prediction markets are platforms where participants trade contracts that pay out based on the outcome of future events (\cite{wolfers_prediction_2004}). These markets aggregate the individual predictions of participants, turning them into a collective forecast of the likelihood that an event will occur. The concept of prediction markets is rooted in the idea that the collective wisdom of a diverse group of individuals, each with access to different information and insights, can generate more accurate forecasts than any individual expert (\cite{bossaerts_price_2022}). These markets function similarly to financial markets (\cite{wolfers_prediction_2004}), where participants buy and sell contracts based on their predictions of future outcomes. For instance, participants might buy a contract that pays out if a specific political event occurs, such as the election of Trump against Kamala Harris during the 2024 presidential race (\cite{mongrain_introduction_2024}), or if a company meets a certain financial target.\\

One of the key features of prediction markets is their ability to aggregate information. As discussed by \cite{bossaerts_price_2022}, these markets incorporate diverse viewpoints, enabling them to reflect the collective intelligence of participants. This phenomenon is often referred to as the "wisdom of crowds". \cite{berg_prediction_2008}, have shown that prediction markets can outperform individual experts in terms of forecasting accuracy, as they incorporate a wide range of opinions. \\

These markets are typically structured as winner-take-all markets or vote-share markets. In winner-take-all markets (\cite{dai_wisdom_2021}), participants predict a single outcome and those who predict the correct event share the prize. This market model offers a fixed payout for the correct prediction, which is typically the same for all winners. Vote-share markets involve trading based on the estimated proportion of votes or shares in a specific outcome, often used for more detailed or continuous predictions, such as estimating the exact vote share in an election or market share in a competition (\cite{dai_wisdom_2021}).\\

Research has shown that prediction markets can effectively predict not only political events but also economic trends, such as the likelihood of a recession or the movement of stock prices (\cite{wolfers_prediction_2004}). These markets function as a tool to forecast economic indicators, company performance, or even geopolitical events. By integrating real-time information and the collective insights of a diverse set of participants, prediction markets offer a unique and valuable source of predictive signals that can inform decision-making in various domains, including finance. For example, Google estimates its market capitalization using prediction markets to forecast its value prior to an initial public offering (\cite{berg_searching_2009}).


\subsection{Conceptual and theoretical framework}

\subsubsection{Efficient market hypothesis (EMH)}

The Efficient Market Hypothesis (EMH), developed by Eugene Fama, posits that asset prices fully and instantaneously reflect all available information (\cite{naseer_efficient_2016}). This theory assumes that markets are highly efficient in processing and integrating information into prices, leaving no opportunity for consistent outperformance based on publicly available data.\\

In this context, prediction markets can be viewed as a mechanism to enhance market efficiency by aggregating dispersed and heterogeneous information from a diverse set of participants (\cite{downey_efficient_2024}). These markets function by incentivizing participants to trade based on their knowledge, insights, or expectations of future outcomes, effectively pooling collective intelligence.\\

Unlike traditional financial markets, which rely on a combination of fundamental and technical analysis, prediction markets are explicitly designed to reflect probabilities of future events (\cite{nti_systematic_2020}; \cite{naseer_efficient_2016}). By doing so, they may uncover "hidden" information that would otherwise remain unintegrated into asset prices. This ability to aggregate a wide array of viewpoints and data sources positions prediction markets as a complementary tool for improving the informational efficiency of financial markets.

\subsubsection{Investor behavior}

\paragraph{Herding :}Herding behavior is a significant phenomenon in financial markets, where investors mimic the actions of others rather than relying on their own private information. This tendency often arises during periods of market stress, leading to deviations of asset prices from their intrinsic values. Research highlights that herding is particularly pronounced in emerging markets, where information asymmetry and market inefficiencies are more prevalent (\cite{ah_mand_herding_2023}). For example, in the Malaysian stock market, evidence suggests that herding behavior exhibits non-linear characteristics, with variations between up and down market conditions. Shariah-compliant stocks tend to demonstrate herding more significantly during upward market movements, while conventional stocks show limited evidence of herding. This behavior has critical implications for market stability, as it may amplify volatility and hinder market efficiency.

\paragraph{Financial influencers :}Financial influencers on social media platforms, particularly those categorized as "mega influencers" with over one million followers, have a unique ability to shape investor behavior and market dynamics. Studies demonstrate that posts from these influencers can significantly affect investor attention, trading volume and stock price volatility (\cite{keasey_impact_2024}). However, their influence on stock returns is limited, requiring posts with extreme sentiment from top influencers to elicit short-lived impacts on returns. This aligns with the "noise trader" hypothesis, which posits that uninformed trading triggered by such influencers introduces temporary mispricing that reverses over time. By analyzing over 16 million Instagram posts, researchers have highlighted the importance of sentiment and engagement metrics, such as comment volume, in amplifying the visibility and potential market impact of influencer content. These findings underscore the dual-edged role of influencers in promoting market participation while potentially fostering instability through noise trading.


\newpage
\section{Methodological framework}
This section of the paper presents the methodological basis for the comparative analysis of forecasting models. It outlines two primary modeling strategies, global versus local approaches, employed to predict stock returns using exogenous signals from prediction markets. The global strategy leverages XGBoost to capture common predictive structures across assets, while local models use ARIMA/ARIMAX formulations to model asset-specific dynamics. The section further grounds this comparison in the bias-variance tradeoff and introduces the associated hypotheses regarding the relative effectiveness of prediction market signals in each approach.

\subsection{Comparative modeling strategy: Global vs. Local approaches}

\subsubsection{Global Model}
\label{sec:xgboost_theory}
In financial time series forecasting, one crucial methodological decision involves the level of aggregation in model training — whether to use a single unified model across multiple assets (global modeling) or to estimate distinct models for each asset (local modeling). This distinction has important implications for model complexity, data efficiency, and forecasting accuracy (\cite{hewamalage_recurrent_2021}). The present research implements and compares both approaches in the context of predicting daily stock returns using signals from prediction markets as exogenous inputs.\\

In this study, a global model is trained on pooled data from all stocks in the dataset. To implement this approach, we employ XGBoost (Extreme Gradient Boosting) — a tree-based ensemble learning method — due to its robustness in handling high-dimensional, heterogeneous data and its ability to capture complex non-linear interactions.\\

The underlying assumption of global modeling is that there exist shared structures in the return-generating processes of different assets — such as macroeconomic influences, investor sentiment, or systemic risk — which can be jointly learned across the cross-section (\cite{hartford_deep_2018}; \cite{gu_empirical_2020}). By training on the entire panel of time series simultaneously, the global model benefits from a substantially larger effective sample size, leading to reduced variance and improved generalization performance (\cite{montero_modelling_2021}).\\

Incorporating exogenous variables, from prediction markets, further strengthens the rationale for a global modeling strategy by leveraging common information signals. Nevertheless, global models may face limitations in capturing asset-specific idiosyncrasies, potentially introducing specification bias when individual stock behavior deviates significantly from the shared structure.\\

XGBoost, introduced by \cite{chen_xgboost_2016}, is well-suited for both regression and classification tasks. It constructs an ensemble of weak learners (typically decision trees) in a stage-wise manner, optimizing a regularized objective function to prevent overfitting and improve predictive accuracy. Formally, the model prediction at iteration \( t \) is updated as:
\[
F_t(x) = F_{t-1}(x) + \eta h_t(x)
\]
\begin{itemize}
  \item \( F_t(x) \): prediction at iteration \( t \),
  \item \( F_{t-1}(x) \): prediction from the previous iteration,
  \item \( \eta \): learning rate,
  \item \( h_t(x) \): decision tree fitted to the residuals at iteration \( t \).
\end{itemize}

The training objective minimizes a regularized loss:
\[
L(\theta) = \sum_{i=1}^{N} \ell(y_i, F(x_i)) + \sum_{t=1}^{T} \Omega(h_t)
\]
\begin{itemize}
  \item \( \ell(y_i, F(x_i)) \): loss function (e.g., squared error),
  \item \( \Omega(h_t) \): regularization term penalizing model complexity,
  \item \( N \): number of observations,
  \item \( T \): total number of boosting iterations.
\end{itemize}

In our framework, XGBoost serves as the global learning algorithm, exploiting both asset-specific features and common predictive signals to forecast returns. Its scalability, regularization capabilities, and effectiveness with sparse or correlated inputs make it an ideal choice for this high-dimensional financial modeling task.


\subsubsection{Local Models}

In contrast to the global approach, local models are estimated independently for each stock in the dataset. This modeling strategy enables the capture of asset-specific temporal dynamics, including individual autoregressive patterns and distinct responses to exogenous signals such as prediction market indicators. For this purpose, we implement ARIMA and ARIMAX models — classical time series techniques introduced by \cite{box_time_2015} — which are particularly effective for modeling univariate or low-dimensional time series with well-defined autocorrelations.\\

The local modeling framework operates under the assumption that each stock reacts to external signals in a firm-specific manner, reflecting heterogeneity across sectors, market microstructure, liquidity, or investor composition (\cite{de_prado_advances_2018}; \cite{tashman_out-of-sample_2000}).

The general form of an ARIMA(\(p, d, q\)) model is:

\[
Y_t = \mu + \sum_{i=1}^{p} \phi_i Y_{t-i} + \sum_{j=1}^{q} \theta_j \epsilon_{t-j} + \epsilon_t
\]

\begin{itemize}
    \item \( Y_t \): observed value at time \( t \),
    \item \( \mu \): intercept (constant mean),
    \item \( \phi_i \): autoregressive (AR) coefficients,
    \item \( \theta_j \): moving average (MA) coefficients,
    \item \( \epsilon_t \): white noise error term,
    \item \( d \): order of differencing applied to ensure stationarity.
\end{itemize}

To incorporate external predictors, the ARIMA model can be extended to an ARIMAX specification, which includes exogenous variables \( X_t \). The general form becomes:

\[
Y_t = \mu + \sum_{i=1}^{p} \phi_i Y_{t-i} + \sum_{j=1}^{q} \theta_j \epsilon_{t-j} + \sum_{k=1}^{m} \gamma_k X_{t-k} + \epsilon_t
\]

\begin{itemize}
    \item \( X_{t-k} \): exogenous variables at lag \( k \),
    \item \( \gamma_k \): coefficients associated with the exogenous predictors.
\end{itemize}

In this study, the exogenous inputs \( X_t \) consist of aggregated prediction market signals that may influence future stock movements. Local models allow for lower bias by tailoring the estimation to individual asset behaviors. However, this benefit comes at the expense of higher variance, especially when the time series for each stock is relatively short, leading to risks of overfitting and parameter instability.\\

Furthermore, from an operational perspective, managing a large number of asset-specific models introduces scalability challenges — particularly in real-time or high-frequency trading environments — due to the computational and maintenance overhead involved in updating models individually.

\subsubsection{Bias-Variance Tradeoff and Model Evaluation}

This dual modeling approach is grounded in the classical bias-variance tradeoff (\cite{geman_bias_1992}). Global models, by pooling data, offer stable predictions with lower variance but may introduce systematic bias if heterogeneity across series is substantial. Local models are more flexible and tailored, potentially reducing bias, but are more prone to variance-driven errors. This empirical analysis evaluates these tradeoffs in the context of out-of-sample forecasting error, using Root Mean Squared Error (RMSE) and the Diebold-Mariano test to compare model performance statistically across assets and time periods.


\subsection{Testable Hypotheses Derived from the Framework}

The following hypotheses guided the empirical investigation:
\begin{itemize}
    \item \textbf{H1:} The informational value of prediction market signals for stock return forecasting is more pronounced in local (stock-specific) models than in global (market-wide) models. This explores whether local models better leverage granular prediction market information.

    % H1 (fr) : La valeur informationnelle des signaux des marchés de prédiction est plus marquée dans les modèles locaux que dans les modèles globaux.

    \item \textbf{H2:} The influence of prediction market signals differs between individual stocks and broader ETFs. This hypothesis examines whether prediction markets have a more direct impact on firm-specific assets compared to diversified instruments that aggregate multiple companies or sectors.

    % H2 (fr) : L'influence des signaux des marchés de prédiction diffère entre les actions individuelles et les ETFs plus larges. Cette hypothèse examine si les marchés de prédiction ont un impact plus direct sur les actifs spécifiques à une entreprise que sur des instruments diversifiés.
\end{itemize}

\newpage
\section{Data and Preprocessing}

This section describes the data sources and the preprocessing steps applied to prepare the datasets for empirical modeling, distinguishing between the procedures used for the global and local modeling strategies. The implementation was done in \texttt{R}, utilizing a wide range of packages including \texttt{tidymodels}, \texttt{modeltime}, \texttt{timetk}, \texttt{tidyverse}, \texttt{KFAS}, \texttt{tseries}, and others. All analyses and source code are available on the following public GitHub repository, which was made publicly accessible to ensure transparency and reproducibility: \url{https://github.com/ixmxdrien/Master-Thesis}.

\subsection{Data Sources}
The empirical analysis is based on three primary categories of data, each serving a complementary purpose in the modeling and evaluation process:

\begin{itemize}
    \item \textbf{Prediction Market Data (Kalshi):} Forecast data were sourced from Kalshi (\url{https://kalshi.com}), a regulated prediction market platform that offers contracts on a broad spectrum of macroeconomic and firm-specific events. The dataset included both quarterly contracts (e.g., Tesla vehicle production, Netflix subscriber growth, Meta daily active users, U.S. GDP growth) and annual contracts (e.g., hurricane counts, SpaceX launches, tech layoffs, Apple car announcements, Ethereum price, measles incidence). Several signals were updated multiple times per day, reflecting real-time changes in market expectations. The data, provided in CSV (e.g., \texttt{kalshi-chart-data-metadap-24-q1.csv}), contained time-stamped forecast values or percentages. Custom parsing functions developed in \texttt{R} were employed to standardize these inputs and resample them to a daily frequency, making them suitable for integration into time series models.

    \item \textbf{Financial Market Data (Delphia):} Stock return data for a curated selection of U.S. equities were provided by Delphia, a data-driven fintech company. These returns, compiled in the file \texttt{tilt\_stocks\_2024.csv}, include daily observations for prominent stocks such as TSLA, NFLX, META, AAPL, NVDA, MSFT, and others. This dataset served as the primary dependent variable for evaluating the predictive power of Kalshi-based signals on individual company returns.

    \item \textbf{ETF Market Data (Yahoo Finance via \texttt{yfinance}):} To investigate whether the relationships observed between Kalshi signals and individual stock returns also extend to broader asset classes, exchange-traded funds (ETFs) were incorporated into the analysis. A Python script leveraging the \texttt{yfinance} library was used to query and download returns data for tree major ETFs:
    \begin{itemize}
        \item S\&P 500 (\texttt{SPY})
        \item MSCI World Index (\texttt{IWDA.AS})
        \item Nasdaq 100 (\texttt{QQQ})
    \end{itemize}
    These ETFs were chosen to represent a range of geographies and sector exposures, allowing the study to explore whether insights derived from Kalshi signals are consistent across both equity-specific and index-based instruments.
\end{itemize}


\subsection{Common Preprocessing Pipeline}
For both the global and local models, the following preprocessing steps were systematically applied:

\begin{itemize}
    \item \textbf{Daily Aggregation:} Raw Kalshi prediction market data came with heterogeneous temporal structures. 
    
    \vspace{10pt}  % Espace pour aérer un peu la présentation

    \begin{center}
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{Timestamp} & \textbf{ticker} & \textbf{Value} & \textbf{quarter} \\
    \hline
    2024-01-26 14:00:00 & Tesla & 481566.5 & Q1 \\
    2024-01-26 15:00:00 & Tesla & 481711.8 & Q1 \\
    2024-01-26 18:00:00 & Tesla & 480876.7 & Q1 \\
    2024-01-26 21:00:00 & Tesla & 480876.7 & Q1 \\
    2024-01-27 00:00:00 & Tesla & 480988.4 & Q1 \\
    2024-01-27 15:00:00 & Tesla & 484911.4 & Q1 \\
    2024-01-27 18:00:00 & Tesla & 485746.9 & Q1 \\
    2024-01-27 21:00:00 & Tesla & 485746.9 & Q1 \\
    \hline
    \end{tabular}
    \end{center}
    
    To ensure compatibility with daily financial returns, all prediction signals were aggregated to a daily frequency using a custom function (\texttt{process\_df\_daily}), as recommended by \cite{campbell1997econometrics} to avoid issues related to intraday error correlation and temporal misalignment between forecast and return series.

    
    \begin{code}[language=R,caption={Test de causalité de Granger entre les séries}]
    process_df_daily <- function(df, ticker) {
    df %>%
        mutate(date = as.Date(Timestamp)) %>% 
        mutate(id = ticker) %>%
        group_by(date, id) %>%
        summarise(pred_daily = mean(Value, na.rm = TRUE))
    }
    \end{code}
    This function computed the mean of all intraday values for each contract and date, producing one representative prediction value per day per event.



    \vspace{10pt}  % Espace pour aérer un peu la présentation
    \begin{center}
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{date} & \textbf{id} & \textbf{pred daily} \\
    \hline
    2024-01-26 & Tesla & 481257.9 \\
    2024-01-27 & Tesla & 484348.4 \\
    \hline
    \end{tabular}
    \end{center}


    \item \textbf{Missing Value Imputation:} The handling of missing data differed depending on the data type:
    \begin{itemize}
        \item \textit{Prediction Market Data:} Between prediction periods (e.g., from Q1 to Q2), some dates were missing due to inactive or unpublished forecasts. To reconstruct a complete daily timeline for each contract, a Kalman filter was applied using a local linear trend state-space model (\texttt{SSModel}) from the \texttt{KFAS} package. The smoothed state estimates filled in the missing values, ensuring temporal continuity across contract boundaries, as recommended by \cite{durbin2012time}.
        
        \item \textit{Financial Market Data:} Stock and ETF return data exhibited missing values corresponding to weekends and public holidays—non-trading days during which markets are closed. After verifying that these gaps aligned with expected calendar closures, no imputation was performed. Instead, \texttt{na.omit()} was applied to clean the dataset, ensuring that only valid trading sessions (typically five days per week) were retained for modeling purposes (\cite{brockwell2016introduction}).

    \end{itemize}

    \item \textbf{Data Integration:} Once the prediction signals and financial return series were processed, the two datasets were merged on the basis of the available trading dates from the financial market data (i.e., stock and ETF returns). This approach ensured temporal alignment and eliminated any potential look-ahead bias, by guaranteeing that only information available at or prior to each trading day was used for forecasting. By anchoring the integration to the financial data timeline, we avoided including future prediction signals that would not have been observable at the time of the actual market movement. The final dataset consisted of: (i) daily asset returns as target variables, (ii) corresponding prediction market signals, and (iii) metadata such as date, asset ticker, and event identifiers.

    \begin{center}
    \small 
    \renewcommand{\arraystretch}{0.8}
    \label{tab:merged_data}
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Date} & \textbf{id} & \textbf{pred daily} & \textbf{ticker} & \textbf{returns} \\
    \hline
    2024-01-29 & Tesla & -470.67267 & AAPL & -1.458257e-03 \\
    2024-01-29 & Tesla & -470.67267 & AMZN & 1.204971e-02 \\
    2024-01-29 & Tesla & -470.67267 & BAC & 6.287425e-03 \\
    2024-01-29 & Tesla & -470.67267 & COIN & 4.508616e-02 \\
    ... & ... & ... & ... & ... \\
    2024-01-30 & Tesla & -838.51256 & AAPL & -1.518802e-02 \\
    2024-01-30 & Tesla & -838.51256 & AMZN & -1.057872e-02 \\
    2024-01-30 & Tesla & -838.51256 & BAC & 2.625369e-02 \\
    2024-01-30 & Tesla & -838.51256 & COIN & -3.844175e-02 \\
    ... & ... & ... & ... & ... \\
    2024-05-22 & Netflix & 0.029503250 & AAPL & -0.0070995761 \\
    2024-05-22 & Netflix & 0.029503250 & AMZN & -0.0040787470 \\
    2024-05-22 & Netflix & 0.029503250 & BAC & 0.0088809947 \\
    2024-05-22 & Netflix & 0.029503250 & COIN & 0.0288876050 \\
    ... & ... & ... & ... & ... \\
    2024-11-26 & Apple & 4.000 & XOM  & -0.0130511169 \\
    2024-11-26 & Apple & 4.000 & SPY  & 0.0052214111 \\
    2024-11-26 & Apple & 4.000 & IWDA.AS & 0.0011463223 \\
    2024-11-26 & Apple & 4.000 & QQQ  & 0.0053692356 \\
    \hline
    \end{tabular}
    \end{center}
        
\end{itemize}
\\

To ensure the integrity of temporal causality and prevent future information from influencing model training or evaluation, the data integration process was anchored to financial market timestamps. This approach ensured that only Kalshi prediction signals published prior to or on the same day as the asset returns were used. Even though future data might technically be available in the full dataset, it was carefully excluded from the training and testing process to avoid any potential look-ahead bias. As recommended by \cite{hyndman2018forecasting}, a walk-forward validation procedure was implemented, involving a strict temporal separation between training and test sets. This reinforced the validity of the forecasting exercise by ensuring that no future information contaminated the model's training or evaluation phases.



\newpage
\subsection{Global Modeling Preprocessing}
In the global modeling framework (\texttt{global\_model.R}), the objective was to uncover generalizable relationships between Kalshi forecast signals and financial asset returns by training a single unified model across all stocks. Unlike the individual asset modeling approach, this method used a common architecture to highlight predictive features consistent across companies, contracts, and time periods.\\

After completing the preprocessing and integration steps, the data were structured as a longitudinal panel dataset encompassing all tickers. Each row corresponded to a unique combination of trading date and stock ticker, with Kalshi signals serving as explanatory variables and daily returns as the target variable.\\

The forecast signals from Kalshi were transformed from long to wide format using the \texttt{pivot\_}
\texttt{wider()} function. Each distinct contract (e.g., \texttt{TSLA\_Q1\_prod}, \texttt{META\_DAU}) was converted into a separate column, resulting in a high-dimensional feature space. Due to the specificity of some contracts to certain companies, missing values were retained and handled directly within the modeling process.\\

To enhance the model's capacity to learn company-specific dynamics, additional categorical metadata such as the stock ticker (\texttt{ticker}) was included as a predictor. These variables were converted into dummy variables using the \texttt{step\_dummy()} function from the \texttt{recipes} package, allowing for the integration of company-level effects within a unified modeling structure.\\

The dataset was sorted chronologically and then divided into training and test sets, ensuring that the test data followed the training period to preserve temporal integrity. This procedure safeguarded against information leakage from the future into the training phase. All preprocessing operations—including imputation, encoding, and normalization—were conducted exclusively on the training set to uphold this separation.\\

Finally, missing values in the Kalshi signals, typically arising from the absence of relevant contracts for certain companies, were left as \texttt{NA}. The XGBoost algorithm was chosen in part for its ability to natively handle missing values, allowing the absence of information to be treated as a potentially informative feature.\\

This global modeling strategy leveraged cross-company variation while enforcing a robust temporal validation design. By training on a diverse, unified dataset that spanned various stocks and contract types, the model was positioned to identify generalizable and transferable patterns that improved both prediction accuracy and model applicability.


\subsection{Local Modeling Preprocessing}
The local modeling approach, implemented in the \texttt{local\_model.R} script, focuses on creating individualized models for each asset, allowing for a more precise capture of asset-specific dynamics. This section outlines the key preprocessing steps applied within this localized framework.\\

For each asset (e.g., TSLA, NFLX, or META), the dataset is filtered to retain only the return series and the relevant Kalshi contracts specific to that stock. This filtering ensures that irrelevant signals are excluded, reducing noise and dimensionality for each model.\\

As local models are particularly sensitive to temporal properties, both the return series and prediction signals undergo stationarity tests. A custom function, \texttt{check\_stationarity}, applies the Augmented Dickey-Fuller (ADF) test recursively, allowing for up to two differencing operations if necessary, to ensure the data satisfies stationarity requirements. If the initial series is non-stationary (p-value \(>\) 0.05), the function applies differencing to achieve stationarity. This process ensures that methods dependent on stationarity are valid. The following R code illustrates the stationarity testing procedure:\\

\newpage
\begin{code}[language=R,caption={Stationarity test with successive differencing}]
check_stationarity <- function(df, ticker) {
  df_clean <- df[!is.na(df$returns), ]
  adf_result <- adf.test(df_clean$returns, alternative = "stationary")
  
  if (adf_result\$p.value > 0.05) {
    df\$returns <- c(NA, diff(df\$returns, differences = 1))
    df_clean <- df[!is.na(df\$returns), ]
    adf_result_diff1 <- adf.test(df_clean\$returns, alternative = "stationary")
    
    if (adf_result_diff1\$p.value > 0.05) {
      df\$returns <- c(NA, diff(df\$returns, differences = 1))
    }
  }
  return(df)
}
\end{code}

In addition to stationarity checks, dynamic predictor selection is performed using Granger causality tests. These tests assess whether each differenced Kalshi signal provides statistically significant predictive information for the asset's return series. If a signal passes a predefined significance threshold (typically set at 5\%), it is retained as a predictor. This step results in a refined and interpretable feature set for each asset. The following code snippet demonstrates how the Granger causality test is applied to identify significant predictors:\\

\begin{code}[language=R,caption={Test de causalité de Granger entre les séries}]
granger_causality_test <- function(pred_series, stock_series, max_lag = 5) {
  df_combined <- inner_join(pred_series, stock_series, by = "date", suffix = c("_pred", "_stock"))
  df_clean <- df_combined %>% drop_na(pred_daily_pred, pred_daily_stock)
  grangertest(df_clean\$pred_daily_stock ~ df_clean\$pred_daily_pred, order = max_lag)
}
\end{code}

Unlike the global approach, the local models did not include any dummy variables for tickers or cross-sectional metadata, as each model pertained to a single stock by design. Instead, lagged features were engineered on a per-asset basis using functions from the \texttt{timetk} and \texttt{recipes} packages. This allowed each model to account for short-term memory and autoregressive effects specific to the asset in question.\\



Temporal integrity was maintained throughout the process by applying walk-forward validation independently to each asset. Each fold respected chronological order, ensuring that validation sets always followed their corresponding training sets in time.\\

This localized modeling strategy enabled a more granular analysis of asset-specific behavior and improved prediction accuracy in contexts where global models might fail to capture nuanced patterns. Although computationally more demanding, this approach provided enhanced interpretability and robustness, especially in the face of heterogeneous predictive signal relevance across assets.

\newpage
\section{Modeling (Implementation)}
This section details the practical implementation of the forecasting models. The primary global model implemented was XGBoost, and local models were ARIMAX, both evaluated within a walk-forward validation framework.

\subsection{Technical specifications of the global model (XGBoost)}

The global forecasting model used in this project is based on the XGBoost algorithm, a powerful gradient boosting technique particularly well-suited for structured/tabular data. This model was previously introduced in Section~\ref{sec:xgboost_theory}, where its theoretical foundations and general properties were discussed. Here, we focus on its practical implementation within a time-series forecasting context. The model is trained and evaluated using a time-series framework with walk-forward validation to preserve the temporal structure of the data. Below are the key steps of the implementation:

\paragraph{Data Splitting and Cross-Validation:}
To evaluate the model's generalization ability, we use the \texttt{time\_series\_cv()} function to implement a walk-forward validation strategy. This method ensures that each training set contains only observations prior to the corresponding testing period. We use two non-overlapping folds with the following configuration:\\

\begin{code}[language=R]
# Creates two non-overlapping time splits with cumulative window
splits <- data_tbl %>%
  arrange(date) %>%
  time_series_cv(
    date_var   = date,        
    initial    = 150 days,  
    assess     = 75 days,   
    skip       = 75 days,   
    cumulative = TRUE,  
    slice_limit = 2   
  )
\end{code}\\

In this section of the code, we create a walk-forward validation strategy using the
\texttt{time\_series}\\ \texttt{\_cv()} function. First, we ensure that the data is ordered by date, which is essential for time-series analysis. The function splits the data into two folds with a training window of 150 days and a testing window of 75 days. The training window is cumulative, meaning each new fold includes all previous data. The \texttt{skip} argument is set to 75 days, meaning the training set for the next fold will start 75 days after the previous fold's test set. Finally, the \texttt{slice\_limit} argument is used to limit the number of folds to 2 for simplicity.

\paragraph{Feature Engineering:}
The \texttt{recipe} function is used to preprocess the data for the XGBoost model. This includes several important steps. First, categorical variables (such as "id") are converted into dummy variables using \texttt{step\_dummy()}. Numeric predictors are then normalized to have zero mean and unit variance using \texttt{step\_normalize()}. Time-based features are extracted with
\texttt{step\_timeseries\_signature()} to allow the model to learn seasonal patterns. The \texttt{step\_rm()} function removes the "date" column after the time-based features are extracted. Next, \texttt{step\_zv()} removes predictors that have near-zero variance, which are unlikely to contribute to the model. Finally, \texttt{step\_dummy()} is applied to nominal predictors to perform one-hot encoding, which transforms categorical variables into a format suitable for machine learning algorithms. This feature engineering strategy follows best practices for panel time series forecasting, as outlined by \cite{modeltime_panel_data}.\\


\begin{code}
# Data preparation pipeline for XGBoost
rec_obj_xgb <- recipe(value ~ ., data = train_data) %>%
  step_dummy(id) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_timeseries_signature(date) %>% 
  step_rm(date) %>%  
  step_zv(all_predictors()) %>%  
  step_dummy(all_nominal_predictors(), one_hot = TRUE)
\end{code}\\


\paragraph{Model Training:}
For each fold, an XGBoost regression model is trained within a \texttt{workflow} using the previously defined recipe. This workflow combines the data preprocessing steps with the model training.\\

\begin{code}
# Creating a workflow combining the XGBoost model with the recipe
wflw_xgb <- workflow() %>%
  add_model(boost_tree("regression") %>% 
  set_engine("xgboost")) %>% 
  add_recipe(rec_obj_xgb) %>%
  fit(train_data) 
\end{code}\\

In this part of the code, an XGBoost model is created using the \texttt{workflow()} function. This workflow integrates the pre-processing steps from the recipe with the XGBoost model. The model is specified as a regression model by using the \texttt{boost\_tree()} function and setting the engine to \texttt{xgboost}. The \texttt{add\_recipe()} function adds the preprocessing steps defined earlier, ensuring that the data is properly prepared before fitting the model. Finally, the model is trained using the \texttt{fit()} function on the training data.

\paragraph{Model Evaluation:}
The model is evaluated using the \texttt{modeltime} framework. For each fold, the calibrated model is assessed on unseen data and its accuracy is reported both globally and by ticker (i.e., for each time series). RMSE is used as the main metric to assess model performance.\\

\begin{code}
# Calibrating the model on the test data
calib_tbl <- model_tbl %>%
  modeltime_calibrate(new_data = test_data, id = "ticker") 

# Calculation of performance (RMSE, etc.) per ticker (id)
calib_tbl %>%
  modeltime_accuracy(acc_by_id = TRUE)  
\end{code}\\

Once the model is trained, it is calibrated on the test data using the \texttt{modeltime\_calibrate()} function. This function evaluates the model's performance on unseen data, and accuracy metrics (like RMSE) are calculated using the \texttt{modeltime\_accuracy()} function. The evaluation is done both globally and by each ticker to assess the model's performance on individual time series, following the procedure recommended by \cite{modeltime_panel_data}.


\paragraph{Final Forecasting and Refit:}
After validation, the model is refitted on the full dataset to produce future forecasts. A 30-day future frame is generated for each ticker, and forecasts with confidence intervals are produced.\\

\begin{code}
# Retraining the model on the entire data set (after validation)
refit_tbl <- calib_tbl_1 %>%
  modeltime_refit(data = data_tbl) 

forecast_results <- refit_tbl %>%
  modeltime_forecast(
    new_data = future_tbl,  
    actual_data = data_tbl,  
    conf_by_id = TRUE 
  )
\end{code}

After model validation, the final model is refitted using the entire dataset with \texttt{modeltime\_refit()}. This allows the model to incorporate all available data, including the validation data, before making future predictions. A 30-day future frame is generated for each ticker, and predictions are made using the \texttt{modeltime\_forecast()} function, which also calculates confidence intervals for the forecasts.

\paragraph{Result Storage:}
Both RMSE metrics and final forecast outputs are saved as RDS files for reproducibility and further analysis. This ensures that results can be easily accessed and shared for future analysis or reporting.\\

\begin{code}
# Saving RMSE results and forecasts
saveRDS(global_rmse_results, "data/rds/global_model_rmse.rds")

# Saving RMSE results for each ticker
saveRDS(forecast_results, "data/rds/global_model_forecasts.rds")
\end{code}\\

The results, including RMSE metrics and forecast outcomes, are saved in RDS files using the \texttt{saveRDS()} function. This ensures that the model's results can be reproduced in the future and shared for further analysis or reporting.


\subsection{Technical specifications of the local model (ARIMAX)}
To study the relationship between stock returns and prediction markets, we have implemented a local modeling approach using ARIMAX, which is an ARIMA model incorporating external explanatory variables. After verifying the stationarity of the data and the influence of the prediction markets on stock returns via the Granger causality test, we can now proceed to the implementation of the ARIMAX model. The approach is structured according to the following steps:


\subsubsection{Time Splitting: Walk-forward Validation}

We used a \textit{walk-forward validation} time splitting method to simulate a real forecasting situation (\cite{hyndman2018forecasting}). The dataset is divided into successive windows, with a training period of 150 days and a test period of 75 days. This procedure is repeated for two folds:

\begin{itemize}
    \item \textbf{Fold 1:} Training data for the first 150 days, testing on the following 75 days.
    \item \textbf{Fold 2:} Cumulative training data (225 days), testing on the following 75 days.
\end{itemize}

\begin{code}
splits <- df_combined %>%
  arrange(date) %>%
  time_series_cv(
    date_var   = date,
    initial    = 150 days,
    assess     = 75 days,
    skip       = 75 days,
    cumulative = TRUE,
    slice_limit = 2
  )
\end{code}

\begin{code}
first_split <- splits\$splits[[1]]
second_split <- splits\$splits[[2]]

train_data_1 <- analysis(first_split)
test_data_1  <- assessment(first_split)
train_data_2 <- analysis(second_split)
test_data_2  <- assessment(second_split)
\end{code}

\subsubsection{Fitting the ARIMAX Model}

Based on the results of the Granger causality test (\cite{granger1969investigating}), two scenarios are considered:
\begin{itemize}
    \item \textbf{No significant exogenous variables:} A simple ARIMA model is fitted.
    \item \textbf{At least one exogenous variable:} An ARIMAX model is fitted with the corresponding predictions as explanatory variables.
\end{itemize}

The exogenous variables are time-aligned with the return series and formatted into a matrix. Additional checks are performed to handle missing values and potential misalignments. In case of an error during fitting, the model defaults to a simple ARIMA model.

\newpage
\begin{code}[caption={Modélisation locale ARIMA/ARIMAX pour chaque action}]
fit_local_model_fold <- function(ticker_data, granger_results, prediction_markets, fold_number) {
  # Extraction of the current ticker
  current_ticker <- unique(ticker_data\$ticker)
  
  # Extraction of significant exogenous variables
  exog_vars <- granger_results %>%
    filter(Stock == current_ticker, result == "Granger-causes", p_value < 0.05) %>%
    pull(Prediction_Market)

  ts_data <- ts(ticker_data\$returns, frequency = 365)

  if (length(exog_vars) > 0) {
    exog_matrix <- prediction_markets %>%
      filter(id %in% exog_vars) %>%
      pivot_wider(names_from = id, values_from = pred_daily) %>%
      arrange(date) %>%
      filter(date %in% ticker_data$date) %>%
      select(-date) %>%
      as.matrix()

    if (any(is.na(exog_matrix))) {
      model <- auto.arima(ts_data)
    } else {
      model <- auto.arima(ts_data, xreg = exog_matrix)
    }
  } else {
    model <- auto.arima(ts_data)
  }

  return(model)
}
\end{code}

\subsection{Forecast Error Evaluation}
\paragraph{Forecast Error Measurement Across Folds:}
For each fold, forecast errors \( e_t = y_t - \hat{y}_t \) were computed for both forecasting approaches. These errors were collected to enable a fair comparison between the global and local models. The goal of this procedure is to apply the Diebold-Mariano test (\cite{diebold1995comparing}) in order to evaluate the statistical significance of the differences in predictive accuracy. This methodology provides insight into whether one model consistently outperforms the other or if the observed differences are due to random fluctuations.


\newpage
\section{Analysis of Results}

\subsection{Implementation of ARIMA and ARIMAX Models}

\subsubsection{Stationarity Assessment}

To ensure valid time series modeling, the Augmented Dickey-Fuller test revealed distinct stationarity patterns across our variables. As shown in Table~\ref{tab:adf_results}, while stock returns were naturally stationary, 11 of 14 prediction market signals required first-order differencing to achieve stationarity. The three exceptions—Meta daily active users, WTI oil prices, and Apple car development—were stationary at level.\\

This pattern, clearly documented in Table~\ref{tab:adf_results}, suggests that prediction markets often reflect cumulative expectations rather than instantaneous shifts, creating persistent trends that require differencing for proper model specification. This preprocessing step was essential to prevent coefficient distortion in subsequent ARIMAX modeling.

\begin{table}[ht]
    \centering
    \begin{tabular}{|l|c|}
    \hline
    \textbf{Pred market} & \textbf{Number of differentiation} \\
    \hline
    TESLA & 1 \\
    NETFLIX & 1 \\
    GDP & 1 \\
    SpaceX & 1 \\
    Gas US & 1 \\
    BTC & 1 \\
    US Semi conductor & 1 \\
    Inflation & 1 \\
    Hurricanes & 1 \\
    Measles & 1 \\
    META & 0 \\
    WTI Oil & 0 \\
    Apple & 0 \\
    \hline
    \end{tabular}
    \caption{ADF test results and required differencing for prediction signals.}
    \label{tab:adf_results}
    \end{table}

\subsubsection{Granger Causality Results}
Table~\ref{tab:granger_causality} presents the pairwise Granger causality test results at 5\% significance, revealing specific predictive relationships between prediction markets and financial assets. As evident from the p-values in Table~\ref{tab:granger_causality}, macroeconomic signals demonstrated broader influence than firm-specific indicators.\\

The GDP prediction market emerged as particularly influential, Granger-causing returns in four assets (IWDA.AS, XOM, SPY, and WMT) with p-values ranging from 0.0233 to 0.0471, as documented in Table~\ref{tab:granger_causality}. Firm-specific prediction signals showed more targeted impacts, with Meta's signals influencing JNJ returns (p=0.0061) and Netflix-related predictions affecting its own stock (p=0.0203).\\

The bottom portion of Table~\ref{tab:granger_causality} displays relationships falling into the marginally significant range (0.05 \(<\) p \(<\) 0.10), including Apple's influence on WMT (p \(=\) 0.0551) and cryptocurrency predictions on tech stocks. While excluded from formal modeling, these near-significant relationships suggest potential areas for future investigation.\\

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|c|l|}
\hline
\textbf{Pred Market} & \textbf{Stock} & \textbf{p-value} & \textbf{Result} \\
\hline
Meta & JNJ & 0.0061 & Granger-causes \\
Hurricanes & GOOG & 0.0081 & Granger-causes \\
Measles & NFLX & 0.0203 & Granger-causes \\
GDP & IWDA.AS & 0.0233 & Granger-causes \\
SpaceX & NFLX & 0.0281 & Granger-causes \\
GDP & XOM & 0.0307 & Granger-causes \\
GDP & SPY & 0.0386 & Granger-causes \\
GDP & WMT & 0.0471 & Granger-causes \\
Hurricanes & TSLA & 0.0485 & Granger-causes \\
Meta & PFE & 0.0530 & Does not Granger-cause \\
Apple & WMT & 0.0551 & Does not Granger-cause \\
ETH & MSFT & 0.0574 & Does not Granger-cause \\
GDP & QQQ & 0.0696 & Does not Granger-cause \\
SpaceX & WMT & 0.0796 & Does not Granger-cause \\
BTC & SPY & 0.0872 & Does not Granger-cause \\
Netflix & PFE & 0.0927 & Does not Granger-cause \\
\hline
\end{tabular}
\caption{Granger-causal links between prediction markets and asset returns.}
\label{tab:granger_causality}
\end{table}

\subsection{Comparative Performance (RMSE)}

\subsubsection{Performance by Model Type}
Tables~\ref{tab:rmse_fold1} and~\ref{tab:rmse_fold2} demonstrate the consistent superiority of local models across both validation folds. As documented in Table~\ref{tab:rmse_fold1}, ARIMA/ARIMAX models outperformed XGBoost in 16 of 19 cases during Fold 1, with this advantage extending to 18 of 19 cases in Fold 2 (Table~\ref{tab:rmse_fold2}).\\


The magnitude of improvement varied considerably across assets, with Table~\ref{tab:rmse_fold1} showing the largest gains for NVDA (RMSE reduction from 0.0300 to 0.0196, representing a 35\% improvement). The exceptions to this pattern appear in both tables: Table~\ref{tab:rmse_fold1} shows COIN, NFLX, and XOM favoring the global model, while in Table~\ref{tab:rmse_fold2}, only MSFT (with a substantial difference of 0.0130 vs 0.0225) preferred the global approach.

\subsubsection{Performance by Asset Type}
Examining Tables~\ref{tab:rmse_fold1} and~\ref{tab:rmse_fold2} by asset categories reveals that ETFs (SPY, QQQ, IWDA.AS) consistently showed smaller absolute errors compared to individual stocks. In Table~\ref{tab:rmse_fold1}, SPY demonstrates an RMSE of just 0.0079 (global) and 0.0070 (local), substantially lower than technology stocks like TSLA (0.0275/0.0244) and NVDA (0.0300/0.0196).\\

Similar patterns appear in Table~\ref{tab:rmse_fold2}, where high-volatility technology stocks show both the largest absolute errors and most substantial local model improvements. TSLA, NVDA, and COIN display the highest RMSE values across both tables, suggesting these attention-driven securities experience both greater volatility and potentially greater benefit from prediction market signals.

\begin{table}[ht]
\centering
\small
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Ticker} & \textbf{Global RMSE} & \textbf{Local RMSE} & \textbf{Better Model} \\
\hline
AAPL & 0.0090 & 0.0083 & Local \\
AMZNI & 0.0154 & 0.0124 & Local \\
BAC & 0.0114 & 0.0112 & Local \\
COIN & 0.0477 & 0.0485 & Global \\
GOOG & 0.0138 & 0.0138 & Local \\
INTC & 0.0220 & 0.0212 & Local \\
IWDA.AS & 0.0083 & 0.0073 & Local \\
JNJ & 0.0112 & 0.0093 & Local \\
JPM & 0.0137 & 0.0129 & Local \\
META & 0.0143 & 0.0126 & Local \\
MSFT & 0.0117 & 0.0098 & Local \\
NFLX & 0.0141 & 0.0148 & Global \\
NVDA & 0.0300 & 0.0196 & Local \\
PFE & 0.0131 & 0.0130 & Local \\
Q00 & 0.0113 & 0.0096 & Local \\
SPY & 0.0079 & 0.0070 & Local \\
TSLA & 0.0275 & 0.0244 & Local \\
WMT & 0.0107 & 0.0092 & Local \\
XOM & 0.0116 & 0.0116 & Global \\
\hline
\end{tabular}
\caption{RMSE comparison: global vs. local models on Fold 1}
\label{tab:rmse_fold1}
\end{table}


\begin{table}[h]
\centering
\small
\begin{tabular}{|l|c|c|l|}
\hline
\textbf{Ticker} & \textbf{Global RMSE} & \textbf{Local RMSE} & \textbf{Better Model} \\
\hline
AAPL & 0.0140 & 0.0128 & Local \\
AMZN & 0.0198 & 0.0157 & Local \\
BAC & 0.0145 & 0.0129 & Local \\
COIN & 0.0511 & 0.0477 & Local \\
GOOG & 0.0157 & 0.0147 & Local \\
INTC & 0.0283 & 0.0275 & Local \\
IWDA.AS & 0.0109 & 0.0097 & Local \\
JNJ & 0.0106 & 0.0102 & Local \\
JPM & 0.0151 & 0.0140 & Local \\
META & 0.0211 & 0.0197 & Local \\
MSFT & 0.0130 & 0.0225 & Global \\
NFLX & 0.0152 & 0.0145 & Local \\
NVDA & 0.0367 & 0.0358 & Local \\
PFE & 0.0128 & 0.0117 & Local \\
QQQ & 0.0164 & 0.0158 & Local \\
SPY & 0.0116 & 0.0107 & Local \\
TSLA & 0.0382 & 0.0357 & Local \\
WMT & 0.0091 & 0.0085 & Local \\
XOM & 0.0133 & 0.0123 & Local \\
\hline
\end{tabular}
\caption{RMSE comparison: global vs. local models on Fold 2}
\label{tab:rmse_fold2}
\end{table}


\newpage
\subsection{Statistical Significance (Diebold-Mariano Test)}

The Diebold-Mariano test results in Table~\ref{tab:DM}  provide statistical validation for the performance differences observed in Tables~\ref{tab:rmse_fold1} and~\ref{tab:rmse_fold2}. Across the 38 test cases documented in Table~\ref{tab:DM}, local models achieved statistically significant superiority (p \(<\) 0.05) in 8 instances, compared to just one case favoring the global model (MSFT in Fold 2, with an extremely significant result of p \(=\) 0.0000).\\

Tech stocks showed the strongest statistical evidence of local model superiority in Table ~\ref{tab:DM}, with AMZN (p \(=\) 0.0328 and p \(=\) 0.0030), GOOG (p \(=\) 0.0187), META (p \(=\) 0.0488), and NVDA (p \(=\) 0.0004) all demonstrating significant results in at least one fold.\\

Notably, Table~\ref{tab:DM} shows that despite the numerical RMSE improvements for ETFs in Tables~\ref{tab:rmse_fold1} and~\ref{tab:rmse_fold2}, none of the three ETFs (SPY, QQQ, IWDA.AS) achieved statistical significance in the DM test. The p-values for these instruments consistently exceeded 0.05 across both folds, suggesting their improvements were not substantial enough to confidently reject the null hypothesis of equal predictive accuracy.

\begin{table}[H]
\centering
\begin{tabular}{|l|l|c|c|l|c|}
\hline
\textbf{Ticker} & \textbf{Fold} & \textbf{DM Statistic} & \textbf{P-value} & \textbf{Conclusion} & \textbf{N Observations} \\
\hline
AAPL & Fold 1 & 0.9791 & 0.3321 & No difference & 53 \\
AAPL & Fold 2 & 1.2352 & 0.2225 & No difference & 51 \\
AMZN & Fold 1 & 2.1936 & 0.0328 & Local  & 53 \\
AMZN & Fold 2 & 3.1257 & 0.0030 & Local  & 51 \\
BAC & Fold 1 & 0.4777 & 0.6349 & No difference & 53 \\
BAC & Fold 2 & 2.0583 & 0.0448 & Local  & 51 \\
COIN & Fold 1 & -0.4358 & 0.6648 & No difference & 53 \\
COIN & Fold 2 & 1.4593 & 0.1507 & No difference & 51 \\
GOOG & Fold 1 & 0.0813 & 0.9355 & No difference & 51 \\
GOOG & Fold 2 & 2.4301 & 0.0187 & Local  & 51 \\
INTC & Fold 1 & 0.5021 & 0.6178 & No difference & 51 \\
INTC & Fold 2 & 0.8389 & 0.4055 & No difference & 51 \\
IWDA.AS & Fold 1 & 1.1126 & 0.2710 & No difference & 53 \\
IWDA.AS & Fold 2 & 1.7427 & 0.0873 & No difference & 53 \\
JNJ & Fold 1 & 4.0505 & 0.0002 & Local  & 51 \\
JNJ & Fold 2 & 0.5103 & 0.6121 & No difference & 51 \\
JPM & Fold 1 & 1.1543 & 0.2539 & No difference & 51 \\
JPM & Fold 2 & 1.7547 & 0.0854 & No difference & 51 \\
META & Fold 1 & 2.0198 & 0.0488 & Local  & 51 \\
META & Fold 2 & 1.2666 & 0.2112 & No difference & 51 \\
MSFT & Fold 1 & 2.7692 & 0.0079 & Local  & 51 \\
MSFT & Fold 2 & -8.1694 & 0.0000 & Global  & 51 \\
NFLX & Fold 1 & -0.9318 & 0.3559 & No difference & 51 \\
NFLX & Fold 2 & 1.1179 & 0.2689 & No difference & 51 \\
NVDA & Fold 1 & 3.8234 & 0.0004 & Local & 51 \\
NVDA & Fold 2 & 0.8141 & 0.4194 & No difference & 51 \\
PFE & Fold 1 & -0.1201 & 0.9049 & No difference & 51 \\
PFE & Fold 2 & 1.3527 & 0.1822 & No difference & 51 \\
QQQ & Fold 1 & 1.8467 & 0.0705 & No difference & 53 \\
QQQ & Fold 2 & 1.2531 & 0.2160 & No difference & 51 \\
SPY & Fold 1 & 1.4017 & 0.1669 & No difference & 53 \\
SPY & Fold 2 & 1.3091 & 0.1965 & No difference & 51 \\
TSLA & Fold 1 & 1.8633 & 0.0683 & No difference & 51 \\
TSLA & Fold 2 & 1.4134 & 0.1637 & No difference & 51 \\
WMT & Fold 1 & 1.6203 & 0.1112 & No difference & 53 \\
WMT & Fold 2 & 0.7302 & 0.4687 & No difference & 51 \\
XOM & Fold 1 & -0.2090 & 0.8353 & No difference & 53 \\
XOM & Fold 2 & 1.4613 & 0.1502 & No difference & 51 \\
\hline
\end{tabular}
\caption{Diebold-Mariano test results for forecast accuracy}
\label{tab:DM}
\end{table}


\subsection{Hypothesis Evaluation}

\paragraph{H1: Local Models Leverage Prediction Market Signals More Effectively Than Global Models.}
Our empirical analysis, summarized across Table~\ref{tab:granger_causality} through 5, provides strong support for H1. The evidence in Table~\ref{tab:granger_causality} confirms significant causal relationships between multiple prediction market signals and asset returns, while Table~\ref{tab:rmse_fold1} and~\ref{tab:rmse_fold2} demonstrate consistent outperformance of local models across validation folds (16/19 and 18/19 cases respectively). This conclusion is further reinforced by the statistical significance established in Table~\ref{tab:DM}, where local models achieved significance in eight cases compared to the global model's single instance.\\


\paragraph{H2: Prediction Market Influence Differs Between Individual Stocks and ETFs.}
For H2, the evidence across these tables offers qualified support. Table~\ref{tab:granger_causality} shows stronger Granger-causal relationships for individual stocks, while Tables~\ref{tab:rmse_fold1}, ~\ref{tab:rmse_fold2}, and Table~\ref{tab:DM} collectively demonstrate that ETFs experienced more limited benefits from prediction market integration. This pattern suggests that prediction market signals may be most effective for concentrated exposures rather than diversified instruments, where signal diffusion may attenuate predictive power.




\newpage
\section{Discussion and Lessons Learned}

The findings of this study shed light on both the methodological challenges and the interpretive value of prediction market signals in financial forecasting. This section synthesizes the main takeaways, organized around two main axes: methodological insights and study limitations.

\subsection{Methodological Insights}

\paragraph{1. Model granularity enhances signal relevance.}
Prediction market signals demonstrate notable predictive potential when integrated into asset-specific models. Global or overly aggregated models tend to dilute the informational content of these signals. In contrast, localized modeling — tailored to individual stocks or narrow asset classes — preserves the contextual relevance of market expectations, leading to stronger forecasting performance.

\paragraph{2. Asset type influences signal effectiveness.}
The predictive value of signals varies across financial instruments. Individual stocks, being sensitive to firm-specific developments, exhibit stronger reactions to targeted prediction market signals. Conversely, ETFs, due to their diversified nature, tend to attenuate these effects. This suggests that prediction markets are better suited for forecasting concentrated, event-sensitive assets rather than broad indices.

\paragraph{3. Statistical causality does not imply forecasting gains.}
While several signals were found to be Granger-causal, this relationship did not systematically translate into improved forecasting performance in ARIMAX models. Effective integration of exogenous signals requires careful design and contextual justification.

\paragraph{4. Comparative evaluation is essential.}
Performance metrics such as RMSE, alongside rigorous tests like the Diebold-Mariano test, enabled a robust assessment of model performance. These tools allowed us to go beyond descriptive comparison and make statistically grounded evaluations of forecasting accuracy, highlighting the importance of methodological rigor in model validation.

\paragraph{5. Data quality and frequency are critical.}
Inconsistent results across certain stocks (e.g., \texttt{NFLX}, \texttt{XOM}) suggest that data frequency and completeness play a central role in model reliability. Gaps or noise in prediction market data — or in the asset return series — can undermine model stability and lead to misleading conclusions. Ensuring high-quality, high-frequency data is thus a prerequisite for dependable forecasts.

\paragraph{6. Limited impact of firm-specific signals.}
Contrary to initial expectations, prediction market signals linked to firm-specific events (e.g., earnings releases) did not consistently Granger-cause stock returns. In contrast, signals related to broader macroeconomic or public health events showed stronger causal relationships. This indicates that the informational reach of prediction markets may be more effective at capturing systemic or widely covered events than narrowly focused corporate news.

\subsection{Limitations and Challenges}

\paragraph{1. Restricted data availability and market maturity.}
Prediction markets remain a nascent domain, with many platforms only recently providing relevant data. This immaturity limits historical depth and reduces the reliability of statistical inference, especially for long-term models or rare event forecasting.

\paragraph{2. Regional access constraints.}
Access to certain prediction markets is geographically restricted, reducing opportunities for data collection and international comparison. For instance, regulatory limitations such as the suspension of Polymarket in Belgium hamper both research breadth and external validation.

\paragraph{3. Narrow asset sample.}
The study was based on a limited set of financial instruments, which constrains the generalizability of our conclusions. Expanding the asset universe to include a broader variety of stocks, ETFs, and asset classes would allow for a more comprehensive understanding of the predictive capacity of these markets.

\paragraph{4. Short observation window.}
Due to the limited historical data, models were estimated over relatively short time frames. This poses risks of overfitting and prevents the identification of longer-term dynamics. Future research should seek to incorporate extended time horizons to enhance model robustness and generalizability.

\paragraph{5. Data preprocessing complexities.}
Prediction market data often require significant cleaning and alignment with financial time series. Missing values, inconsistent update frequencies, and event classification ambiguities all introduce potential biases. Improved data engineering practices — from standardized signal extraction to temporal alignment — are necessary for more reliable forecasting pipelines.

\paragraph{6. Issue of contemporaneity and reverse causality.}
Although causality tests (such as Granger causality) were employed, it remains possible that prediction market signals are themselves influenced by stock price movements, rather than the other way around. This introduces a risk of reverse causality or contemporaneous effects, particularly when the predicted events are widely covered by financial media.



\newpage
\section{Conclusion}
This thesis investigated the relationship between prediction market signals and stock returns through a comparative modeling framework. By contrasting global and local forecasting approaches, we sought to determine whether prediction markets generate informational value for financial forecasting and under what conditions this value is most pronounced.\\

Our findings provide compelling evidence that prediction market signals can enhance the accuracy of stock return forecasts, particularly when implemented within asset-specific models. The empirical analysis demonstrated that local models (ARIMA/ARIMAX) consistently outperformed the global model (XGBoost) across most assets and validation folds, with statistically significant improvements observed in several cases according to the Diebold-Mariano test. This pattern highlights the importance of model granularity in capturing the nuanced relationships between specific prediction market signals and individual asset returns.\\

The research also revealed distinct patterns in how prediction market signals influence different types of financial instruments. Individual stocks showed stronger reactions to targeted prediction signals compared to diversified ETFs, where the effects were more diffuse. This dichotomy suggests that prediction markets may be most valuable for forecasting concentrated, event-sensitive assets rather than broadly diversified indices.\\

From a methodological perspective, this study contributes to the financial forecasting literature by demonstrating how alternative data sources like prediction markets can be systematically integrated into time series models. The walk-forward validation framework, combined with rigorous statistical testing, provides a robust template for evaluating the incremental value of novel predictive signals in financial applications.\\

For Delphia and similar data-driven investment firms, these findings have practical implications. The integration of prediction market signals into asset-specific models could enhance forecasting precision, particularly for stocks with clear connections to forecasted events. However, the inconsistent performance across assets suggests that careful selection and preprocessing of signals is necessary to extract maximum value.\\

Future research should extend this analysis by incorporating longer time horizons, a broader range of assets, and additional prediction market platforms. Investigating market microstructure effects, liquidity considerations, and the temporal stability of predictive relationships would further enrich our understanding of how prediction markets and financial markets interact. Additionally, exploring deep learning approaches that can capture complex, non-linear relationships between prediction signals and returns may yield further improvements in forecasting accuracy.\\

In conclusion, prediction markets represent a valuable but nuanced source of information for financial forecasting. Their effectiveness depends critically on modeling strategy, asset characteristics, and implementation details. When appropriately integrated, these signals can provide meaningful enhancements to traditional forecasting methods, offering investors new avenues to extract informational advantages in financial markets.


\newpage
\printbibliography

\newpage
\chapter*{Appendix}

\section{Figures}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/example_figure1.png}
    \caption{Exemple de figure 1}
    \label{fig:example1}
\end{figure}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{figures/example_figure2.png}
    \caption{Exemple de figure 2}
    \label{fig:example2}
\end{figure}

% Include the title page PDF
\includepdf[pages={1}]{end_page.pdf}

\end{document}

